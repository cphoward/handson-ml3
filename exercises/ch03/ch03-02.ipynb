{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2df82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import shift, rotate, affine_transform, map_coordinates, gaussian_filter\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    # dx: +right / -left, dy: +down / -up\n",
    "    im = image.reshape(28, 28)\n",
    "    return shift(im, shift=[dy, dx], mode=\"constant\", cval=0.0, order=1).ravel()\n",
    "\n",
    "def rotate_image(image, degrees):\n",
    "    # degrees: positive = counter-clockwise\n",
    "    im = image.reshape(28, 28)\n",
    "    return rotate(im, angle=degrees, reshape=False, mode=\"constant\", cval=0.0, order=1).ravel()\n",
    "\n",
    "def scale_image(image, scale):\n",
    "    # isotropic scaling around center; keep canvas 28x28\n",
    "    im = image.reshape(28, 28)\n",
    "    # affine matrix for scaling: output[x, y] = input[(x-cx)/s+cx, (y-cy)/s+cy]\n",
    "    s = float(scale)\n",
    "    cx = cy = 13.5\n",
    "    M = np.array([[1/s, 0, cx - cx/s],\n",
    "                  [0, 1/s, cy - cy/s],\n",
    "                  [0,   0,        1 ]])[:2, :3]\n",
    "    return affine_transform(im, matrix=M[:, :2], offset=M[:,2], output_shape=(28,28),\n",
    "                            order=1, mode=\"constant\", cval=0.0).ravel()\n",
    "\n",
    "def shear_image(image, shear_x=0.0, shear_y=0.0):\n",
    "    # small shear (±0.1–0.2). Matrix maps output coords to input coords.\n",
    "    im = image.reshape(28, 28)\n",
    "    cx = cy = 13.5\n",
    "    Sh = np.array([[1, -shear_x, 0],\n",
    "                   [-shear_y, 1, 0],\n",
    "                   [0, 0, 1]])\n",
    "    # center the transform\n",
    "    T1 = np.array([[1,0,-cx],[0,1,-cy],[0,0,1]])\n",
    "    T2 = np.array([[1,0,cx],[0,1,cy],[0,0,1]])\n",
    "    A = (T2 @ Sh @ T1)[:2, :]\n",
    "    return affine_transform(im, matrix=A[:,:2], offset=A[:,2], output_shape=(28,28),\n",
    "                            order=1, mode=\"constant\", cval=0.0).ravel()\n",
    "\n",
    "def elastic_deform(image, alpha=34, sigma=4):\n",
    "    \"\"\"\n",
    "    Classic elastic deformation:\n",
    "    - alpha controls intensity (displacement magnitude)\n",
    "    - sigma controls smoothness (Gaussian filter std)\n",
    "    Values above are conservative for MNIST 28x28.\n",
    "    \"\"\"\n",
    "    im = image.reshape(28, 28)\n",
    "    rng = np.random.default_rng()\n",
    "    dx = gaussian_filter(rng.standard_normal(im.shape), sigma, mode=\"reflect\") * alpha\n",
    "    dy = gaussian_filter(rng.standard_normal(im.shape), sigma, mode=\"reflect\") * alpha\n",
    "    x, y = np.meshgrid(np.arange(28), np.arange(28), indexing='xy')\n",
    "    coords = np.vstack([ (y + dy).ravel(), (x + dx).ravel() ])\n",
    "    deformed = map_coordinates(im, coords, order=1, mode=\"constant\", cval=0.0).reshape(28, 28)\n",
    "    return deformed.ravel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f77a8a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_batch(X, y, max_aug_per_image=2, rng=None):\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    X_aug, y_aug = [X], [y]\n",
    "    for img, label in zip(X, y):\n",
    "        k = rng.integers(1, max_aug_per_image+1)\n",
    "        for _ in range(k):\n",
    "            op = rng.choice([\"shift\",\"rot\",\"shear\",\"elastic\"], p=[0.4,0.3,0.2,0.1])\n",
    "            if op == \"shift\":\n",
    "                dx, dy = rng.choice([-1, 1]), 0\n",
    "                if rng.random() < 0.5: dx, dy = 0, rng.choice([-1, 1])\n",
    "                aug = shift_image(img, dx, dy)\n",
    "            elif op == \"rot\":\n",
    "                deg = rng.choice([-10, -7, 7, 10])\n",
    "                aug = rotate_image(img, deg)\n",
    "            elif op == \"shear\":\n",
    "                sx = rng.uniform(-0.12, 0.12)\n",
    "                aug = shear_image(img, shear_x=sx)\n",
    "            else:  # elastic (rarer)\n",
    "                aug = elastic_deform(img, alpha=34, sigma=4)\n",
    "            X_aug.append(aug); y_aug.append(label)\n",
    "    return np.concatenate(X_aug), np.concatenate(y_aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80cbcaf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cphoward/Development/cphoward/handson-ml3/.venv/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_iterations: 6\n",
      "n_required_iterations: 6\n",
      "n_possible_iterations: 6\n",
      "min_resources_: 625\n",
      "max_resources_: 20000\n",
      "aggressive_elimination: False\n",
      "factor: 2\n",
      "----------\n",
      "iter: 0\n",
      "n_candidates: 48\n",
      "n_resources: 625\n",
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n",
      "----------\n",
      "iter: 1\n",
      "n_candidates: 24\n",
      "n_resources: 1250\n",
      "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
      "----------\n",
      "iter: 2\n",
      "n_candidates: 12\n",
      "n_resources: 2500\n",
      "Fitting 3 folds for each of 12 candidates, totalling 36 fits\n",
      "----------\n",
      "iter: 3\n",
      "n_candidates: 6\n",
      "n_resources: 5000\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "----------\n",
      "iter: 4\n",
      "n_candidates: 3\n",
      "n_resources: 10000\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "----------\n",
      "iter: 5\n",
      "n_candidates: 2\n",
      "n_resources: 20000\n",
      "Fitting 3 folds for each of 2 candidates, totalling 6 fits\n",
      "Best params (tuning subset): {'leaf_size': 30, 'n_neighbors': 4, 'p': 2, 'weights': 'distance'}\n",
      "Baseline test accuracy (no augmentation): 0.9759\n",
      "Augmented test accuracy: 0.9805\n",
      "Error-rate change vs baseline: -19%\n",
      "↓ A negative value indicates the augmented model reduced the error rate (a salutary improvement).\n"
     ]
    }
   ],
   "source": [
    "# Full MNIST pipeline: fetch → tune → baseline → augment → final train → evaluate\n",
    "# ---------------------------------------------------------\n",
    "# Notes:\n",
    "# - We use conservative augmentations (±1 px shifts) that reflect natural handwriting variation.\n",
    "# - HalvingGridSearchCV (successive halving) gives efficient hyperparam tuning.\n",
    "# - KNN benefits from augmentation but gets slower as the dataset grows; adjust the subset sizes if needed.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Enable successive halving search\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Fetch & prepare MNIST\n",
    "# -----------------------------\n",
    "mnist = fetch_openml(\"mnist_784\", version=1, as_frame=False)\n",
    "X, y = mnist[\"data\"], mnist[\"target\"].astype(np.uint8)\n",
    "\n",
    "# Normalize pixel intensities to [0,1] (KNN distance benefits from uniform scale)\n",
    "X = X.astype(np.float32) / 255.0\n",
    "\n",
    "# Standard split: 60k train, 10k test (stratified to preserve class balance)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=10_000, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Utilities: shift augmentation\n",
    "# -----------------------------\n",
    "from scipy.ndimage import shift\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    \"\"\"\n",
    "    Shift a 28x28 image by (dx, dy) with zero-fill (black background).\n",
    "    dx: +right / -left\n",
    "    dy: +down  / -up\n",
    "    \"\"\"\n",
    "    im = image.reshape(28, 28)\n",
    "    shifted = shift(im, shift=[dy, dx], mode=\"constant\", cval=0.0, order=1)\n",
    "    return shifted.ravel()\n",
    "\n",
    "def augment_four_translations(X_arr, y_arr):\n",
    "    \"\"\"For each image, create four shifted copies: left, right, up, down by 1 px.\"\"\"\n",
    "    X_aug = [X_arr]\n",
    "    y_aug = [y_arr]\n",
    "    for dx, dy in ((-1, 0), (1, 0), (0, 1), (0, -1)):\n",
    "        shifted_block = np.vstack([shift_image(img, dx, dy) for img in X_arr])\n",
    "        X_aug.append(shifted_block)\n",
    "        y_aug.append(y_arr)\n",
    "    X_out = np.concatenate(X_aug, axis=0)\n",
    "    y_out = np.concatenate(y_aug, axis=0)\n",
    "\n",
    "    # Shuffle to avoid block structure\n",
    "    idx = np.random.default_rng(123).permutation(len(X_out))\n",
    "    return X_out[idx], y_out[idx]\n",
    "\n",
    "# -----------------------------\n",
    "# 3) Hyperparameter tuning (successive halving on a subset)\n",
    "# -----------------------------\n",
    "# You can increase 'tune_n' to use more data for tuning (tradeoff: time).\n",
    "tune_n = 20_000\n",
    "rng = np.random.default_rng(123)\n",
    "subset_idx = rng.choice(len(X_train), size=tune_n, replace=False)\n",
    "X_tune, y_tune = X_train[subset_idx], y_train[subset_idx]\n",
    "\n",
    "param_grid = {\n",
    "    \"n_neighbors\": [3, 4, 5, 6, 7, 9],\n",
    "    \"weights\": [\"uniform\", \"distance\"],\n",
    "    \"p\": [1, 2],            # 1=Manhattan, 2=Euclidean\n",
    "    \"leaf_size\": [15, 30],  # small effect, but can matter for speed\n",
    "}\n",
    "\n",
    "base_estimator = KNeighborsClassifier(n_jobs=-1)\n",
    "halving = HalvingGridSearchCV(\n",
    "    base_estimator,\n",
    "    param_grid=param_grid,\n",
    "    factor=2,            # how aggressively to halve\n",
    "    resource=\"n_samples\",\n",
    "    max_resources=tune_n,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    refit=True,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "halving.fit(X_tune, y_tune)\n",
    "best_params = halving.best_params_\n",
    "print(\"Best params (tuning subset):\", best_params)\n",
    "\n",
    "# -----------------------------\n",
    "# 4) Baseline: train on original X_train with tuned params\n",
    "# -----------------------------\n",
    "knn_baseline = KNeighborsClassifier(**best_params, n_jobs=-1)\n",
    "knn_baseline.fit(X_train, y_train)\n",
    "baseline_acc = accuracy_score(y_test, knn_baseline.predict(X_test))\n",
    "print(f\"Baseline test accuracy (no augmentation): {baseline_acc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5) Augment training set (±1 px shifts), retrain & evaluate\n",
    "# -----------------------------\n",
    "X_train_aug, y_train_aug = augment_four_translations(X_train, y_train)\n",
    "\n",
    "knn_aug = KNeighborsClassifier(**best_params, n_jobs=-1)\n",
    "knn_aug.fit(X_train_aug, y_train_aug)\n",
    "aug_acc = accuracy_score(y_test, knn_aug.predict(X_test))\n",
    "print(f\"Augmented test accuracy: {aug_acc:.4f}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6) Comparative report\n",
    "# -----------------------------\n",
    "baseline_err = 1.0 - baseline_acc\n",
    "aug_err = 1.0 - aug_acc\n",
    "if baseline_err > 0:\n",
    "    err_rate_change = (aug_err / baseline_err) - 1.0\n",
    "else:\n",
    "    err_rate_change = 0.0\n",
    "\n",
    "print(f\"Error-rate change vs baseline: {err_rate_change:.0%}\")\n",
    "print(\"↓ A negative value indicates the augmented model reduced the error rate (a salutary improvement).\")\n",
    "\n",
    "# -----------------------------\n",
    "# (Optional) Quick sanity visual on a few augmentations\n",
    "# -----------------------------\n",
    "def demo_augment(n=6):\n",
    "    sample = X_train[:n]\n",
    "    titles = [\"orig\", \"left\", \"right\", \"down\", \"up\"]\n",
    "    figs = []\n",
    "    for i in range(n):\n",
    "        variants = [\n",
    "            sample[i].reshape(28,28),\n",
    "            shift_image(sample[i], -1, 0).reshape(28,28),\n",
    "            shift_image(sample[i],  1, 0).reshape(28,28),\n",
    "            shift_image(sample[i],  0, 1).reshape(28,28),\n",
    "            shift_image(sample[i],  0,-1).reshape(28,28),\n",
    "        ]\n",
    "        figs.append(variants)\n",
    "    plt.figure(figsize=(10, 2*n))\n",
    "    for r, row in enumerate(figs):\n",
    "        for c, im in enumerate(row):\n",
    "            ax = plt.subplot(n, 5, r*5+c+1)\n",
    "            ax.imshow(im, cmap=\"Greys\", interpolation=\"nearest\")\n",
    "            ax.axis(\"off\")\n",
    "            if r == 0:\n",
    "                ax.set_title(titles[c], fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# demo_augment()  # uncomment to preview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9db7cc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAASmCAYAAADRUNNzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABQ+klEQVR4nO3debRmZXUn4H2pAopiqGKSmcKRqEBAxogolIpiO5AgmAhEDArYtFFcSkMAIQECiIRZUFEQBFsiAsrShiiFgFZMcAlqjCAsmQQMkamAKqCqbv/hakyRsz/vubXvNz7PWr1Wsw/n+w74e++tn8e879j4+Ph4AAAAACVW6PUDAAAAwDBRtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStPvMvffeG6uttlo8/vjjvX4UmFKbbbZZXHXVVRP6ew866KBYa621Yv3115/ah4Ie2mOPPeIzn/nMhP7eG264IWbPnj21DwQ9ctVVV8Vmm23W68cAWC6Kdp/ZdNNN48knn4xZs2b1+lGgL9x8883xta99LX71q1/FQw89FBdddFFsvfXWvX4sKPftb387/uf//J8ln2WdAEBvKdp95Lnnnuv1I0Df+dWvfhWbbrqp//KJoTY+Ph5Llizp9WMAAEUU7S74zW9+E/vss0+su+66semmm8ZRRx0Vixcvfv5/+nfeeefFpptuGq997Wvj7rvvjrGxsXjsscciIuKZZ56JQw45JNZaa6148YtfHF/4whdibGws7r777p7+M0Gl73znO7HDDjvE7Nmz49WvfnV84xvfiIiIs846Kz74wQ/GT3/601httdXiXe96VxxyyCHP//Vqq60W9957b4+fHiZns802i5NOOil22mmnmDlzZrzoRS+KM8444/nrX/va1+JlL3tZzJo1Kz74wQ/G29/+9jjuuOOW+YwLLrggNtlkk1h77bXj8MMPj4iIH//4x9YJA+X++++P3XffPdZYY43Ydttt4+c///nz17I/Q0X87v/c4vzzz4+IiMcffzymT58eRxxxRET87r+8WnfddeNHP/pRRESMjY3F+eefH1tssUWsscYa8c53vtP/mR4Da2xsLG699dbn//qMM86IXXfddZnrZ555Zmy++eYxe/bseM973iPvPaBod8F73/veWHHFFeNXv/pV3HTTTXHVVVfFpz71qYiIWLBgQdx2223xi1/8Ir73ve/9t3tPOOGEuOWWW+Lf/u3f4tZbb40rr7yy248PU+onP/lJ7L333nHyySfHI488Ep/97Gdj//33j9tvvz3++q//Os4///zYcsst48knn4yrr756mb9+8sknY9NNN+31PwJM2kUXXRRf+tKX4sknn4zNN9/8+fkdd9wR+++/f5xzzjnx29/+NnbYYYe49tprl7l3wYIF8fOf/zx++ctfxs033xznnntu3HDDDbHNNttYJwyU9773vbHBBhvEQw89FJdeeml8/vOfX+Za9meo3XbbLebNmxcRv9u3YLPNNnv+r3/yk5/EkiVLYptttnn+sy6//PK4/vrr49577437778/Tj/99C7+U0J3XXLJJTFv3ry4++6749FHH42PfvSjvX6kkaNoT7Ff//rXcf3118c//MM/xGqrrRZz5syJo446Ki666KKIiFi6dGmcfPLJMXPmzJg5c+Z/u/+yyy6LI444IjbYYIOYNWtWHHvssV3+J4Cp9dnPfjYOOOCAmDt3bqywwgrxute9Lt7+9rfH5Zdf3utHgyn3oQ99KDbffPOYNm1arLTSSs/Pv/rVr8Yb3/jGeOtb3xrTp0+PD37wg/GKV7ximXvHx8fjhBNOiBkzZsQrX/nKeO1rX/v82zsYFPfdd1/cdNNNceqpp8bMmTPjj/7oj+KQQw6JiD/8Z6jddtstbrjhhoiIuP766+MjH/lI3HXXXfHEE0/E9ddfH294wxtihRV+/0fdww8/PF70ohfF7NmzY6+99rJeGGqHH354bLjhhjF79uw4/vjj47LLLoulS5f2+rFGyvReP8Cwu//++2PGjBmx3nrrPT97yUteEvfff39ERKy++uodd4594IEHYpNNNnn+r72VYNjcfffdcf3118eFF174/Gzx4sWxxhpr9PCpoDuyn+kv/Nnf9PeuscYay/wXtKuuumosWLCg/iFhCj3wwAMxY8aMeNGLXvT8bM6cORHxh/8M9ZrXvCYWLVoU//Zv/xbXX399HHLIIfHd7343brrpprj++utj9913X+a7/uvJFdYLw+7/r6P///9/9tln4+GHH15mPTG1vNGeYhtvvHEsWrQofvOb3zw/u/vuu2PjjTeOiFjmv2ltsuGGG8Z99933/F/7v7Nj2GyyySbxkY98JB577LHn/9+TTz4Z5513XuPf/4fWDAySLM8v/Nkf0e7nv3XCoNhwww1j0aJF8R//8R/Pz/5/1v/Qn6GmTZsWr3/96+OrX/1qPPLII/HKV74y5s6dG//0T/8UN954Y+y2227d/YeBLll11VXj6aeffv6vH3zwwf/299xzzz3P///vvffeWGmllWLdddftyvPxO34TT7GNNtoodtttt/j4xz8eTz31VNx7771x4oknxvve974J3f8Xf/EX8alPfSoeeuihePzxx+P444+f4ieG7jr44IPjwgsvjHnz5sWSJUvimWeeifnz58e///u/N/796623Xjz44IOxcOHCLj8pdM8+++wT3/nOd+K6666LxYsXxxe/+MW44447Jny/dcKg2GSTTWLnnXeOI444IhYuXBi33357fPazn42Iif0Zarfddoszzzwz3vCGN0RExNy5c+PCCy+MGTNmxBZbbNGTfyaYaq95zWvikksuicWLF8ett94al1xyyX/7e0499dR44IEH4rHHHotPfvKT8ed//uf+S9gu82+7Cy677LJYuHBhzJkzJ3beeef4H//jfzy/O+wfcvTRR8cf//Efx6te9arYeuut421ve1tERKy88spT+cjQNdtss0185StfiaOPPjrWXXfd2GijjeKYY46JZ555pvHvnzt3buy0006x0UYbxezZs/2vPBhKm2++eXzpS1+KD33oQ7H22mvH/PnzY+7cuRP+2W+dMEguu+yyuO++++JFL3pRvPe9742/+qu/WuZapz9D7bbbbvHEE0/E3LlzIyJiiy22iFVWWcXbbIba2WefHfPnz4/Zs2fH//7f/7vxBd5+++0Xu+22W8yZMydWX331OPPMM3vwpKNtbHx8fLzXD8HEzZ8/P3bddddYtGhRjI2N9fpxAOiSzTffPD75yU/Gvvvu2+tHAaCPjY2NxY9//OPYeuute/0oI80b7T73H//xH8//T2ofeOCBOPLII2OvvfZSsgGG3De/+c1YsGBBPPPMM3HaaafFgw8+GG9961t7/VgAwAQo2n1uyZIlcdhhh8WsWbNi6623jo022ijOPvvsXj8WAFPs2muvjTlz5sQ666wTX/nKV+Ib3/hGrL322r1+LABgAvxPxwEAAKCQN9oAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQtN7/QAAAACjavHixY3zZ599Nr3nHe94R+N83rx5jfPx8fH0s/bdd9/G+cUXX5zes8IK3tf+If4NAQAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACg0Nh4p73emRBb8jOKstxH5NnPch/RPvtZ7iPy7Ms9/aRyDWXrJ8IaAugHzzzzTHrtwAMPbJx/5Stfaf09a621VuP8kUceaf1Zv/zlL9NrL3nJS1p/3qjxGxMAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJBdxyfIToGMqiz7We4j+jf7ck8vdGMNZesnwhqi/zithVHU6ef6fvvt1zifPn16es+NN97YOF9zzTUb5zvvvHP6WdnviY997GPpPaeeemp6jd/xUwMAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIXyPeNZxte//vX0WrZdf6+35D/vvPPSe2zJz0Rl2e90TEWW/Sz3Ee2z3+nIoiz7ck8vdGMNZesnwhqiN7p1LOraa6/dOO+U7+x7/u7v/i69x9F2TNTTTz/dOD/++ONbf9aHP/zh9NqOO+7Y6rO+853vpNfe9KY3Nc5f+tKXtvoOluWNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIbuOv4CdAhlFWe4jarPfNvcRefaz3EfIPt1nDcGynNbCqPrEJz7ROL/99ttbf9bRRx+9vI/zvD/+4z9Or2XPtsYaa5R9/yjyRhsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIXGxsfHx3v9EP3k0EMPbZyff/75rT/rt7/9bXpt9uzZrT8vkx1T0WlL/k5HaDB6stxH1Ga/G7mPyLMv90wVa4hRlR1tt91226X3ZEcJHXbYYek9n/70p1s912233ZZey46263QU3yGHHNLq+xluv/71r9Nrr3jFKxrnixYtSu/ZaaedGuff+9730nv8PO5/3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABQayV3H7RTIqMqyn+U+Is9+lvuIPPtyz6CzhmBZTmthmC1cuLBx/uY3vzm9Z/78+Y3z7bffPr0nWy9bb711/nD0PW+0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKDfUWitlOge95z3vSe7LdYTvtFHjuuec2zu1QSa+0zX6nXfWz7Ge5j5B9Blu2fiKsIUZTp9NaLrrootafl+24v9pqq7X+rMlYa621uvI9DL5HH320cZ7tLN7JjjvumF6zu/hw8kYbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFhvr8EFvyM6q6kX25Z1hl6yfCGmK4ORYVlnX22WeXfdZee+1V9lkMBm+0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKDfX2jnYKZFTJPkxe5fqJsIYYHE5rYVQtWbKkcf7QQw+1/qz3ve99jfNOa4Lh5I02AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKDcXxXrbkZxRluY9on/0s9xGyz/Dqxu+OCGuIweFoSEbVlVde2Ti/+OKLW3/W4Ycf3jhfeeWVW38Wg80bbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQkOx67idAhlFWe4j2mc/y32E7DO8uvG7I8Iaov84rQWWdc899/T6EXrq1ltvbZxfd9116T2XX3556+/Zc889G+d77LFH43zbbbdt/R39xBttAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUGorjvWzJf2vj3Jb8w03ub02vZdmvzH2E7A86a+jW9Fo31lC2fiKsoanmWFQYfLfffnvj/JOf/GTj/Pvf/376Wb/97W8b588++2z7B+vgxz/+ceP8+OOPb5wfffTR6WcddthhjfPVVlut/YNNEW+0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKDcWu44PIToH9v1Mg9bLcR7TPfpb7iNrsZ7mPaJ/9LPcRss/EtP3dEdG/ayhbPxHW0FSz4/6tjXOntVBh8eLFre/55S9/2Th/zWtek96zaNGixvnSpUtbf//MmTMb5zNmzGj9WePj4+m1BQsWNM6zf2fHHXdc+lnXXHNN4/y73/1uek+3f094ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUMiu4y9gp0A7BY6iytxH5NnPch/RPvtZ7iNqs5/lPqJ99rPcR+TZl/vB0Os1VPm7I6I7a6jTvzNriBdyWovTWqZSthP84Ycf3vqzst3m99tvv/SeM888s3H+9NNPt/7+rbbaqnHe6c/lb3zjGxvnk8nXkiVL0muXXHJJ4/yv//qvG+dPPfVU+lm33HJL4/zkk09O7znhhBPSa1PBG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABQaG+90ntOA+PnPf94433LLLVt/1otf/OLG+WS25H/iiSdaf/+obMmfOfLII9Nr3d6Sv99luY9on/0s9xF59rPcR3Qn+1nuI2qzn+U+ojvZl/up043fHRHdWUPZ+ono3zWUrZ8Ia2iqnXbaaY3zyRxldNtttzXOt9hii/Sefj0Wdfr09qfeTuZY1MnYbrvtGueORa2RHTeYHav2mc98Ziof53ljY2Pptb//+79vnB900EGN89mzZ1c80pS46aabGue77rpr68961atelV770Y9+1DhfaaWVWn/PRHijDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQaCh2HbdTYG8N606B/S7LfUT/Zj/LfYTsZ9nPch8xutmv0vZ3R0T/rqFs/UT07xrK1k+ENTTVnNbitBYm5pFHHmmcr7vuul35/k5d4otf/GLjfIcddmj9PZtttlnjfMaMGa0/69FHH02v3XnnnY3zv/3bv22cf/vb3279/fvuu2967cILL2ycT5s2rfX3TIQ32gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKDQUx3tlbMlvS/5R1a/Zz3If0T77We4jarOf5T6iO9nPch8h+1MlWz8R/buGKn93RHRnDWXrJ8IammqORe0tx6IOjmyt3Hbbbek973znOxvnDz30UMkzTYVtttmmcb7mmmu2/qxf/vKX6bX77ruv9edl5syZ0zg/66yz0nve/va3l33/RHijDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQaKh3HbdToJ0CR1Xb7Ge5j+jf7Ge5j6jNfjdyH5FnX+67L1s/EdZQJ9bQ4OvXEysinNaScVpL/1mwYEHj/G/+5m/Se7q1s/+g6ZTvk046qXG+0UYbTdXjtOaNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACg318V6TYUv+OoO+Jf8oyXIfkWdf7nNZ9rPcR8j+oLOGallDveFYVMeiMnWWLFmSXrvooosa552OfHvta1/bOH/44Ycb55/61KfSz9p9993Ta5nrrruucX7KKaek92RrLPuZv+KKK6afNQjH1HmjDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQyK7jE2SnwNHbKZDfybKf5T4iz36W+4j22a/MfUSe/U670LbNvtyPpm6soWz9RPTvGup0MoU1NDic1lLHaS0wXLzRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAoZNdxAABKOa3FaS0w6rzRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIcd7AQAAQCFvtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgELTe/0AAAAALOu+++5Lr/3sZz9rnF911VWN8/nz56eftc466zTO119//fSe448/vnH+kpe8JL1nbGwsvTaMvNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACg0Nj4+Pt7rhxhWdgpkVGXZz3If0T77We4j8uxnuY/Isy/39ELbNZStnwhrCKAfLF26NL323e9+t3F+zDHHpPf88Ic/XO5nmgoPPvhgeq1TNxlG3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQ470myJb8o7clP7+TZT/LfUSe/X7NfUSefblneVlD1hAT41hUhkFWrd74xjem98ybN69x3ilDb3vb2xrnr3vd6xrnf/7nf55+1v333984v/nmm9N7zjzzzMb5n/3Zn6X3nHvuuem1YeSNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIbuOv4CdAu0UOIo6/RjIsp/lPiLPfpb7iPbZz3IfkWc/y31Enn25ZyJ6vYay9RNhDdEbTmux4/6oyrK60047pffMmTOncX7RRRel9+y6665tHmtSnn322fTaDjvs0Di/884703t+8YtfNM433njjdg82ILzRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAoZNfxF7BToJ0CR1Gn3Vyz7Ge5j8iz343cR+TZz3IfkWc/y32E7PN71lD7NWT9DAentTitZRRddtll6bXTTz+99edla2K11VZr/VmVOvWCl7/85a0/7yMf+Ujj/Iwzzmj9WYPAG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABQayeO9bMlvS/5RlWW/MvcR/Zv9ytxHyP4osob87mBZjkV1LOowW7x4ceN8jz32SO957LHHGufXX399es/qq6/e6rmqZXXwYx/7WHrPZH6G33DDDY3zN7zhDa0/axB4ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUGh6rx9gKmU7BV544YWtP6vTToG93h022ynw3HPPLf2eP/3TPy39PKZON7Lfr7mPqM2+3I+ebP1EWEOTYQ0Nvsmc1rLddtul9/TraS333ntveu22225r/Xmf/vSnG+d23B8cl19+eeP8O9/5TnrPv//7vzfOe72zeCdf+9rXGueTyepaa62VXtt6661bfdbTTz+dXps5c2arz+oFb7QBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBoqI/3siX/Ga0/y5b8w6Ft9rPcR/Rv9rPcR9Rmv23uI/Lsy/1gyNZPhDXUiTU0+ByL6lhUBt/ChQsb5x/+8IfTey666KKy7//CF76QXps1a1arz/r2t7+dXttrr71afVYveKMNAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBoqHcdH0R2CmRUtc1+Ze4j8uy3zX1Enn25Z6pk6yfCGmLinNZyRuvPcloLL3TwwQc3zk877bT0nltuuaX19yxatKhxfvzxxzfOH3nkkdbf0cmb3/zmxvk73vGO1p/13e9+t3H+3HPPtf6sfuKNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACjne6wVsyW9L/lGU5T4iz35l7iO6k/0s9xGyz/Lp9RrK1k9E/66hbP1EWENMnGNRmUpz585tnK+//vrpPTfeeGPjfPvtty95pm7acsst02tXX31143zatGmtvyc72m58fLz1Z/UTb7QBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAoN9a7jdgq0U+Coapv9LPcRw5X9LPcRss/vZesnwhqqXEPZ+omwhgaJ01qcWDHMsp/5//Iv/5Le0yn7lf71X/+1cf6DH/yg9WfNmDGjcX7hhRem96yyyiqtv2fUeKMNAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBoqHcdt1OgnQJHVdvs9zr3Ee2zn+U+Is++3DMRnU6m6Nc1VPm7I8IaGlVOa3FaCxOzySabpNfOOOOMsu958MEH02tbbLFFq8/q9DP/3HPPbZxvu+22rb6DZXmjDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQkN9vFfGlvyMqiz7lbmPyLPfNvcRefaz3EfIPlPHGmKYORbVsaj0xrPPPts4P+aYY9J7HnnkkVbfcfzxx6fX/uqv/qrVZzEx3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABQayV3Hq9kpkFGU5T4iz37b3Efk2Zd7Bp01xKBwWgtMrTPPPLNx/oUvfKH1Z6233nqN8w984AOtP4vl4402AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKOd6rgC35GUVZ7iNkHyaicg1l6yfCGqL/OBaVUbRkyZL02hVXXNH688bGxhrnRxxxRON89uzZrb+D5eONNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIbuOT5CdAhlVWfYrcx8h+wyvbqyhbP1EWEP0H6e1MIouv/zy9NoPf/jD1p+3/fbbN84/+tGPtv6sfjVnzpxeP8Jy8UYbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFHO81Qbbkb2/Qt+Tnd7LsV+Y+QvYZXt1YQ8O0fiKsoWHgWFRG1aOPPto4P/TQQ0u/5/TTTy/9vH6044479voRlos32gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhew6/gJ2Cqwz6DsFjpIs9xG12R+F3EfI/iiyhmpZQ4PPaS3t2W1/OHzmM59pnHf6PZHZeeed02udTnIZNNtuu23jfIUVBvud8GA/PQAAAPQZRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFLLr+AvYKbC9Yd0pcJRkuY+ozf4w5T5C9vk9a6i9bP1EWEODxGktdey2Pzgef/zx9NoZZ5zR+vNmzZrVOD/nnHPSe1ZcccXW39OvNtxww14/wpTwmwwAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIXGxsfHx3v9EN3WaUv+l73sZY3z//zP/0zvybbkv+GGG9J7tt566/QaTJUs+1nuI/LsZ7mPyLMv9ww6awiWdeKJJzbOjz766Naf1elY1Hnz5jXOB/GIowceeKBxvsEGG6T3jI2NTdXjMAkPPfRQeq3Tf46ZXXbZpXF+4403tv4s+oc32gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhab3+gF6YeHChem1TruLZ7baaqvGud1h6TdZ9itzHyH7DC9riFHU6bSWM844o/XnZTvun3POOek9g7i7eGbDDTfs9SOwnNZff/302gge6ETCG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABQaG7cHPQAAiYceeii9tsEGG7T+vF122aVxfuONN7b+LIB+5Y02AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhu44DAABAIW+0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQaHqvHwAAAGBULVmypHH+N3/zN+k9p556aqvveMc73pFeO++88xrnG264YavvYFneaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoNDY+Pj4eK8fYtDZkp9RlOU+Is9+29xH5NnPch8h+wwGawiAiIinn366cb766quXfUenyjdnzpzG+fz589N71l9//eV+pmHnjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCG7jhewUyCjKMt9RHeyn+U+Is++3NNPrCFGldNaYFn33Xdf43yzzTYr+45OXWJsbKxxvvHGG6f3/PCHP2yc+z3xe95oAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkOO9CtiSn1GU5T6iO9nPch+RZz/LfYTs033WEKPKsaiwrIsvvrhx/v73v7/sOybTJTo5+OCDG+f/8A//kN4zY8aM1t8zyLzRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAoNL3XDzAM5s2b1+tHaHT//fen1/7u7/6ucW6nQCaqX3MfkWc/y31Enn25Z6pYQ4yq3/72tz39/nvvvbdxvuOOO6b3OK2F5fXUU0+l1z73uc9N+fdvtdVW6bUTTjihcf6ud70rveeSSy5pnN98883pPaeeemrj/A1veEPjfNB/f3ijDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQaGx8fHy81w8xCDrtFPiWt7ylcT5//vyy799yyy3Ta5PZKXDmzJmN8xe/+MXpPaO2UyC/k2U/y31Ed7Kf5T4iz36W+4g8+1nuI2SfibGG2v3uiLCGht3FF1/cOH//+99f9h2d/ng7NjbW+vMOPvjgxrnTWqiwzTbbNM5vu+229J5NNtmkcX7BBRe0+o6IiHXWWadxfu2116b3HHLIIY3ze+65J73nbW97W+P80ksvbZzPmjUr/axB4I02AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKTe/1AwyKVVddNb2WHd3S6WiJbmzJ/61vfSu9J9uS/2c/+1l6z9lnn90432mnnRrnjrUYDln2Ox15l2U/y31E++xnuY/Is5/lPiLPfpb7CNlnYrqxhrL1E9G/ayhbPxHW0DDolO/Pfe5zU/79W221VXptMseiXnLJJY3zm2++Ob3HsahM1Lx58xrnzz33XHrPiSee2DifO3du43zatGmtn6vTMZQHHnhg4/zXv/51es95553X+hkGmTfaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFxsY7bY3NhDz22GON88nsFHjaaac1ziezU2An2Y6bdgpkorLcR+TZz3If0Z3sZ7mPyLMv90yVyjWUrZ8Ia4j+k+2Ef9ttt6X3dOO0lmuvvTa9J9tx/5577knvedvb3tY4v/TSSxvns2bNSj8LXmiDDTZonB977LGN806nRixevLhx/vd///fpPSeffHLjfOONN07vueOOO9Jrw8gbbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFJre6wcYBrNnz259z1e/+tXG+R/90R81zvthS374rypzH9E++1nuI/LsZ7mPkH26rxu/OyKsIfrPvHnzGueTORZ17ty5jfPJHGv3lre8Jb124IEHNs4di0q/+fjHP94432GHHdJ7vvCFLzTOzz///PSelVdeuXF+5plndni60eKNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAobHx8fHxXj/EKNpggw0a5wsWLGic33jjjelnVe4UeMUVV6T37LHHHuk1mIgs9xHts5/lPiLPfpb7iDz7ck8/afu7I8IaYjhk2T/22GMb5/1wWssdd9yRXoPlle0ufvrppzfOO1W+sbGx1t+frYlPfOITrT9rWHmjDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQtN7/QCjat99922cZ1vyb7fddulnTWZL/r/9279tnDuGhamU5T6iffYrcx8h+wyGtr87Iqwhhlt2xNEOO+yQ3lN5LOqZZ57Z4elg+SxcuDC9dttttzXOs2O8Oh3vteKKKzbOr7nmmvSeN7/5zek1fscbbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQnYdn0J2CmRUZdnPch/RPvtZ7iPy7Ms9g6LtGur0O8IaYhg4rYVh9rOf/axx/s53vjO955577mmcTybfq6yySuN8yy23bP1Z/J432gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhew6XsBOgYyiLPcRefaz3Ee0z36W+wjZZzBUrqHK3x0R1hC94bQWhtlPf/rT9NrrX//6xvkTTzzR+nuy3x8777xzes+JJ57YOD/66KPTey644IJ2DzaCvNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhx3tNkC35GVVZ9rPcR3Qn+1nuI/Lsyz290I011Ok4SWuIfuNYVAbd4sWL02vHHXdc4/z0009P71m0aFHjfLPNNkvv+dSnPtU433PPPRvn06ZNSz9rjTXWaJyfc8456T0LFixonK+++urpPaPGG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEIjueu4nQLtFDiqsuxnuY/Is5/lPiLPfpb7iPbZz3IfkWc/y32E7DMx/bqGsvUTYQ3RG05rYZhdfvnl6bWTTjqpcT4+Pp7e86Y3valxfvXVV6f3ZLvnT8a73/3uxvmnP/3p9J4DDjigcX7FFVdUPNJQ8EYbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFxsY77TU/pC677LL02v7779847+ct+R955JHG+U477ZTes+WWWzbObck/3LLsZ7mPyLOf5T4iz343ch+RZz/LfYTsMzHWkDU0iobtWNTPfe5zjfNOx6J+//vfb5w71m40dTr26vDDD2+cH3jggek9n//855f7mabCLbfckl7bYYcdGuf//M//3PqeYeWNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAoem9foBeeOCBB9Jr2e6w/bxT4FprrdU477S7erbr37/8y7+0vofBkWW/0676Wfb7NfcRefY7ZTjLvtzzX1lD1tAouvzyy9NrJ510UuO8n09refe7390477ST9AEHHNA4t9v+aBobG2t97bDDDpuqx5kyr371q9Nr2e+Qo48+Or3nuuuuW+5nGiTeaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoNBIHu9lS35b8o+qLN+d1sQwZb/TcUZZ9uWe/8oasoZGkWNRHYvK8vvLv/zL9Nr555/fOL/nnnvSex555JHG+TbbbNM4f/nLX55+1i9+8YvG+bHHHpve8+ijjzbOOz3zqPFGGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACg0EjuOj4ZdgpkVGXZz3Ifkecoy31E++xnuY/Is5/lPkL2mTrdWEPZ+omwhlh+TmtxWgvLOuigg9JrP/jBDxrn3/ve99J7dtxxx+V+pj9k9dVXT68tXbq0cf7UU0+l96y88sqN8//1v/5XuwcbYt5oAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUGsldx+0UaKfAUZVlP8t9RJ79buQ+Is9+lvuIPPtZ7iNkn4mxhqwhJsZpLQyzTn8uv+KKKxrnd911V3rPOeec0zg/66yz2j1YB0888UR6bebMmY3zT3ziE+k9b3nLWxrnu+22W7sHG2LeaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoNDY+Pj4eK8fYhD0ekv+Tv8xZVvydzpqxZb8TFSW/Sz3Ed3Jfpb7iDz7We4jZJ+pYw0x6BYsWJBeO+CAAxrnnY5FzY7KqtStY1FPOeWU9J4Pf/jD6TVg+HmjDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQyK7jAACUcloLMOq80QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCHHewEAAEAhb7QBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhab3+gEAAACYuMWLFzfOL7744sb5gQcemH7WHnvs0Ti/8sor03tWXnnlDk9HhDfaAAAAUErRBgAAgEKKNgAAABRStAEAAKCQog0AAACFxsbHx8d7/RCjyE6BjKIs9xHts5/lPiLPvtwz6Nr+7oiwhgCG0SmnnNI4P+qooxrnnSrf2NhY4/z73/9+es+OO+7Y4emI8EYbAAAASinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFHO/VI7bkZxRluY9on/0s9xF59uWeQdf2d0eENcRwcCwqo+iEE05Ir5122mmN8wULFjTOJ9Ml3v72t6f3/J//838a5zNmzEjvGTXeaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFJre6wcYZpPZKbDSSSedlF6zUyBTKct+N3IfkWc/y32E7NNfrCFYVpb9bMf9FVbI3yVdd911jfNbb701vceO+/TCo48+ml7LdhevtO6666bXVlxxxSn//kHnjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCG7jk8hOwUyqrLsdyP3EXn25Z5BYQ0xipzWAsvafPPNe/r9Rx99dHpt2rRpXXySweSNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACjneawrZkp9R1a/Zl3sGhTXEKHIsKixr99137+n3r7XWWj39/kHnjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCG7jk8hOwUyqmQflo81xCjq1932I+y4T2+cffbZXfmeddZZp3G+wgreyS4P//YAAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFDI8V5TyJb8jKpuZD/LfYTsM/isIUaRY+2gNw499NDG+aqrrtrlJxkufpMCAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABSy6/gQsFMgoyjLfYTsw0RYQ/Qbp7UAw8RPFAAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFHK8FwAAI8OxqEA3eKMNAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFDIruMAAAB9Znx8fFLXmixdujS9tvvuu7f6LCbGG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEJ2HZ9CdgpkVGX5bpv7iDz7cs8ws4YAGBsbm9S1JiuskL9f3XrrrVt9FhPjjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAo53msK2ZKfUZXlu23uI/Lsyz3DzBpiFDkWFRgm3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABSy6zgAAD3ntBZG1TPPPNM4v/fee7v8JFTyRhsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUc71XAlvyMoiz3EbIPE2ENARAR8fjjjzfOr7zyyi4/CZW80QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKGTX8QJ2CmQUZbmPkH2YCGuIUeW0Fugv3/jGNxrne++9d5efZLh4ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKO9xoCtuRnFGW5j5B9mAhriF5xLCosq9Nxj91w/vnnN87f+c53pvesvPLKU/U4Q8MbbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQnYdL2CnQEZRv+Y+Is++3NNPrCHoDae10G/+8z//s3G+2mqrpfc8+eSTU/U4FPFGGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkF3HC9gpkFGU5T4iz77cw+9ZQ4yqft1x32kt9Mqf/MmfNM4PPfTQ9J5TTjml7PvPPvvsxrncLx9vtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUGhsfHx8vNcPMayOOuqo9FrbLfk7/cf005/+tHH+qle9qtV3QJUs+5M5iiLLfpb7CNln8FlDDLP58+c3zvfYY4/0nrZH23X6c9Ouu+7aOP/Wt76V3uOYI3phwYIF6bU111yz1Wftueee6bWvfvWrjfNp06a1+g6W5Y02AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhu45PITsFMqqy7LfNfUSe/Sz3EbLP4LOGGEVOawGGiTfaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAo5HgvAAB6zrGowDDxRhsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJBdxwEAAKCQN9oAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACg0vdcPAAAAwLIWL16cXrvzzjsb5zvssEPjfMGCBeln7b///o3zLbfcssPTNfvABz6QXltzzTVbf94g80YbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFxsbHx8d7/RDDypb8jKos+1nuI9pnP8t9RG325Z5eaLuGsvUTYQ0BDKobb7wxvTZ37txWn9Wp8o2NjbX6rMk68sgjG+dHHXVU43zGjBlT+ThTzhttAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCdh2fQnYKHOydApm8LPttcx+RZ7/XuY+QfabOKKyhbP1EWEOjymktDIPHHnuscf6hD30ovSf7eTxv3rz0nocffrjVc730pS9Nr911112tPmuyst9He+21V+P8S1/6UvpZq6yySskzTSVvtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUMjxXi9gS/7cqG3JP0qy3Efk2e90NFCW/ba5j8iz3+vcR7TPvtwPL2so1/Z3R4Q1NKoci+pYu0HR6c+4xx57bOP8vvvuS+/pRiY7/Z7qdBxeW+edd1567cQTT2ycZ//8X/nKV9LP2nvvvds9WA94ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUGgkdx23U2DOToHDLct+lvuIPPvd2rU1y35l7iPy7Ge5j2iffbkffNZQru0a6vTPbw0NDqe15JzWMvguvfTSxvkHPvCB9J7nnnuucd7rnfCvuOKK9Nq73vWuKf/+iIjjjjuucX7CCSc0zrfccsv0s77//e83zmfOnNn6uaaKN9oAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIWGetdxOwXWGrWdAgdZ2+xnuY/Is9+tHZOz7Pc69xHts5/lPkL2+0m2fiKsoclo+7sjwhrqN05ryTmtZTg88sgjjfM/+ZM/aZzfeeedrb9j6dKl6bW11lqrcb799tun9+y///6N8ywrK620Uoen646nnnqqcb7eeus1zhcuXJh+1uWXX944z3b17wVvtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUGgojveyJX93jNqW/P0uy31Ed7Kf5T4iz36W+4j+zX6W+4j22c9yHyH7vdD2d0dE/66hTkf/9OsaytZPhDXUK45FreVY1P6yaNGi9Nq2227bOL/99tvLvv+Vr3xleu2mm25qnM+ePbvs+/vZxz72scb5WWedld6T/T684IIL0numTZvW7sGWkzfaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFBmbXcTsF9q9h3SmwX2TZz3If0Z3sZ7mPkP0s+512Xc+yP6q5r9R2DVWunwhrKJOtnwhraKo5raU7nNbSX77+9a+n1/bZZ5+y7znllFMa5zvvvHN6z0477VT2/YNoMl0ic9ddd6XX5syZ0/rzloc32gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKDS91w8wUd/61rfSa5VHsUxmS/5ROIal2iWXXNI4P+6449J7ur0lf7/Ist+N3Efk2Zf79rLcR+TZH9XcV7KGhoc1NHGdjkXdZZddGufZsThjY2Otv3+LLbZIr43Ksairrrpq4/yggw5qnHc6yuiaa65pnO+5557pPY62W9ZVV11V9ll/+Zd/mV477LDDGucrrOD9ZuaDH/xg43wyx3v94z/+Y3rt4x//eOvPWx7+EwcAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKDQwu47bKbB/DetOgf2iG9nPch8h+510I/ujmvtK1lB/ytZPhDVUwWktw8VpLcvv0ksvTa+13Vl/zTXXTK/5md/erFmzev0IU0ISAAAAoJCiDQAAAIUUbQAAACikaAMAAEAhRRsAAAAKKdoAAABQaGCO97Ilf/8a1i35+0WW/ba5j8izL/eTI/uDwRrqT9bP1HIsav9yLGpvLF26NL3WNq/j4+PL+zj8Fz/4wQ8a54P+79lPQQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQgOz67idAvvXsO4U2C+y7E9mR1f/mdSS/cFgDfWnbP1E+PdcwWkt/cuO+73RKatt18RkTq0gYsmSJY3za665pnE+6P+e/XQEAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACg0MLuO2ymw90Ztp8B+kWV/Mv9+/WfSXpb7CNkfFNZQb7X93RHh33MFp7X0LydW9MbLXvay9Npdd93V6rP23Xff5X2ckbRw4cLG+Ze//OUuP0l3eKMNAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCA3O8ly35e2/UtuTvF1n22+Y+QvYnI8t9hOwPCmuot/zu6A3HovaeY1H7ywc+8IH02pFHHtk4f/nLX944f8UrXlHyTKPm2GOPnfLv2G+//ab8OybKG20AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEIDs+u4nQJ7b9R2CuwXWfaz3EfIfqVu5D5C9qdS2zWUrZ8Ia2gyrKHecFpL79lxv79MpktsscUWjfOZM2eWPNMw+sQnPpFeO+OMMxrnk9lx/+CDD26cr7feeq0/a6p4ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEJDfbyXLfnbsyV//5nM8V6y316W/Sz3Ee2zn+U+QvanUts1lK2fCGuok7ZrqPJ3R4Q19EKORe09x6L2l5VWWim9NmPGjMb517/+9cb5pZdemn5WdhzeCiv09v3m0qVL02u/+c1vGuedjqI7/fTTW31Wp2eYzL+bPffcs3E+md8tU8UbbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQgOz67idAu0UOKqy7Ge5j2if/Sz3Ef2b/U5ZzbKf5b7T53Vae23/3WS5j5D9qdR2DWXrJ8IaqlxDlb87IqyhF3JaS3c4rWVwrLrqqum1efPmNc7f8pa3NM7f//73p581f/78xvnRRx/d4enau+uuuxrnV155ZeN84cKF6Wd9/vOfL3mmiM75zn7uZz9jOv3O2WWXXdo9WA94ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEJj4+Pj471+iOX1r//6r43zbEv+J554Iv2sgw46qHE+Klvyd5JFZTJb8u+3336N805HVrGsLPcR7bOf5T6iNvtZ7iPaZ7/XuY9on/0s9xGy3wttf3dE9O8aytZPRP+uoU5HRllDy++pp55Kr2VHQmVZueiii9LPcixqd45F/b//9/82zt/85je3/iwm7qijjmqcn3LKKa0/q9OfJ7pxPGGvvz8iP27z6quvbpwPer690QYAAIBCijYAAAAUUrQBAACgkKINAAAAhRRtAAAAKDQUu45n7BRYa9R2Chxk3ch+t3LX6+/Pch8h+8MqWz8R1tBktP3dEWENTTWntfTnjvtOa+k/zzzzTOO808kvWSbPOOOM9J5B7BLbbbdd63tOOumkxvluu+3W+rMGgTfaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFhnrXcTsF5uwUONzaZj/LfUSe/UHcMbky9xGyP6yy9RNhDfndMdyc1lLLaS38V0899VTre/7pn/4pvXbnnXc2zk844YTG+Zve9Kb0s3baaafG+d57753es8EGG6TXMp1OchlG3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKDQUB/vVcmW/KO3JT+/U5n9LPcR7bOf5T4iz77c0wvdWEPZ+omwhpg4x6LmHG0HtOWNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIbuOAwBQymktdtyHUeeNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACjneCwAAAAp5ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAoNL3XDwAAAMCyvvnNb6bX9txzz8b5jBkzGudnn312xSNNiV133bVxfvnll6f3HHXUUY3zgw8+OL3nM5/5TKvnWl7eaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFLLr+BSyU+Bg7xTI5GXZz3IfMRrZz3IfkWdf7kdT2zWUrZ+I/l1D2fqJsIaA0XLfffc1zvfZZ5/0nrGxscb5M8880zg/6KCD0s8aHx9v9R3Vst9hixYtSu/Jnu2JJ54oeaYK3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQ470K2JJ/OLfkp7Ms9xF59jtlsm32s9z/oe+p1Db7nZ5L9kdP5RrK1k9E/66hTkeSWUOjybGojkUdVbfddlvj/Lnnnuvyk/TGu971rsb5zJkz03v+8R//sXHe6RjIbvNGGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkF3HC9gpcDh3CqSzLPcRsp9lP8t9hOyPolFfQ9n6ibCGhp3TWpzWMoquvfba9Np+++3X+vOyn5NXXXVV43zLLbds/R3dMmvWrMb5Civk74RPOeWUxvlaa61V8kwVvNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACg0Np5tvcgyOu0U+J73vKdx/uSTT6b3jPpOgdkumf20UyC/k2U/y31Env1OO9GPQvY77Q4r+8OrG2soWz8R/buGsvUTYQ0Nu2uuuaZxvueee3bl+3u963i29idzWsv8+fPTe175yle2ezBKPPXUU43zXXbZJb3nJz/5SevvueCCCxrnBxxwQOvPYmp4ow0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKO93oBW/IzirLcR+TZr8x9hOwz2Hq9hqwf+o1jUXOORR1u2c/jL3/5y60/66UvfWl67Uc/+lHjfLXVVmv9PUwNb7QBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAApN7/UD9JtDDz20cT6Z3WE77RT47ne/u/XnwVTJch9Rm325Z1hZQ4yqbMf9I488Mr2n0+7imbPOOqtxPnfu3NafNYjsLt5ffvGLX6TXvvGNb5R9z3vf+9702tNPP904X7RoUeN8nXXWKXkmJs4bbQAAACikaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFBrJ471syc+oyrJfmfuIPPtZ7iNkn8HQr2soWz8R1hBTy7GojKKTTz45vfbEE0+Ufc/xxx/f+tpKK63UOP/Qhz6UftaJJ57YOJ8xY0aHp+MP8UYbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKDQ2Pj4+HivH6LbDjjggPTal7/85e49SAM7BTKVsuz3OvcR7bOf5T5C9pk6/bqGsvUTYQ2x/Dqd1vLa1762cT6ZnZePOeaY9FqW4xVWaH5nZLd9ptKrX/3q9Nrtt9/exSep8frXv75xfs0116T3rLLKKo3zsbGxkmcaBt5oAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCijYAAAAUUrQBAACg0Ege72VLflvyj6os+8OU+4g8+1nuI2SfibGGrKFR5FhUWNaDDz6YXtt+++0b5wcddFB6z5w5c1o/w+OPP944/9jHPtb6s7I62Onn+qOPPto4X3311Vt//7DyRhsAAAAKKdoAAABQSNEGAACAQoo2AAAAFFK0AQAAoNBI7jpup0A7BY6qLPtZ7iPy7FfmPqJ99jv96Mqyn+U+QvaZmH5dQ5W/OyKsIZbltBantTA4nnnmmcb5zJkz03uWLl3aOF9hhfyd7Lx58xrnnU60GDXeaAMAAEAhRRsAAAAKKdoAAABQSNEGAACAQoo2AAAAFBrJXcf7mZ0CGVVts5/lPiLPfpb7CNlnsGXrJ8IaYvk5rcVpLQyOLN/PPvtses+f/umfNs6vu+669J6VVlqpcX7fffel96y99trptWHkjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAo53qvP2JKfUdU2+1nuI/LsZ7mPyLMv9wyCTr/KrSGGmWNRmUpbb71143ybbbZJ7zniiCMa55tvvnnFI02JL37xi43zTsf0ZQ477LD02qmnntr68waZN9oAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIWm9/oBptIg7hQ4NjbWOF955ZXTe9797nc3zjvtOp7tQnvyySen94zaToGDrG32s9xH9G/2s9xH5NnvtHt/ln25Hz3Z+ono3zWUrZ8Ia4jhlu2E//TTT6f3TOa0lre+9a2Nc6e1DIeHH364cX7XXXc1zn/2s5+ln/Wb3/ymcf71r389vWfGjBkdnm6wbLbZZr1+hL7hjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAoNxfFetuSvY0v+wZHlPqJ99rPcR+TZH6bcR8j+KGr7uyPCGurEGhp8jkV1LOqo+uY3v9k4X7hwYevPynJ06KGHpvd88pOfbJzPmTOn9fdPxh133FH2Wfvss0/ZZw06b7QBAACgkKINAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAoNxa7jdgq0U+AoynIf0T77nXZazbKf5T6iO9mvzH2E7I+ibvzuiLCG6D9Oa6ljt/3h8Gd/9meN849+9KON86effrr1d3zpS19Kr1199dWt5hERO++8c+tnyGQ75Ge7+jMx3mgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKDQ2Pj4+HivH2J5PfbYY43zTTfdtHE+mS35O5k9e3bjvFtb8k+bNq1xPpkt+R988MH02rrrrtv685g6We4jupP9LPcRefa7kfuI2uzL/fBq+7sjwhrqxBoaHF/84hcb5wcddFDZd7zvfe9Lr/X6WNQjjjiicf7pT3+69Wf5c9Nwe/WrX904v/3227vy/dtss0167Z//+Z8b5w899FDj/Ljjjks/K/uZ0Ol3QXYk2iWXXJLes/LKK6fXhpE32gAAAFBI0QYAAIBCijYAAAAUUrQBAACgkKINAAAAhYZi1/GMnQLtFDiq+jX7We4j2mc/y31Env0s9xF59uV+9GTrJ6J/11C2fiKsIf47p7U4rYWJefjhhxvnr3vd69J77rrrrrLvX3PNNdNre++9d+P8c5/7XOvvyergGmuskd7zve99r3G+1VZbtf7+YeWNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAoaHeddxOgXYKHFVts1+Z+4g8+1nuI9pnv9OPriz7We4jZJ/fy9ZPRP+uocrfHRHW0Kjq1xMrIpzWQn/p9Hti7ty5jfM77rgjvWfJkiXL/UzLY6WVVmqc33LLLek9r3rVq6bqcYaGN9oAAABQSNEGAACAQoo2AAAAFFK0AQAAoJCiDQAAAIUUbQAAACg01Md7ZWzJb0v+UZVlP8t9RJ79fs19RJ59uWd5WUPW0DBzLKpjUZk6119/fXrtox/9aOP85z//edn3/8Vf/EV67Zhjjmmcv+IVryj7/lHkjTYAAAAUUrQBAACgkKINAAAAhRRtAAAAKKRoAwAAQKGR3HV8MuwUyKjKsp/lPqI72c9yHyH79BdriEHntBY77gPteaMNAAAAhRRtAAAAKKRoAwAAQCFFGwAAAAop2gAAAFBI0QYAAIBCjvcCAKCUY1GBUeeNNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIbuOAwAAQCFvtAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUEjRBgAAgEKKNgAAABRStAEAAKCQog0AAACFFG0AAAAopGgDAABAIUUbAAAACinaAAAAUOj/AcF0QATWsYBgAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x1200 with 30 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "demo_augment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b75eecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Baseline (no augmentation) ==\n",
      "[baseline] Test accuracy: 0.9759\n",
      "\n",
      "== Variant A: Four-shift augmentation ==\n",
      "[four-shift] Training on 300,000 samples (orig 60,000)...\n",
      "[four-shift] Test accuracy: 0.9805\n",
      "[four-shift] Error-rate change vs baseline: -19% (negative is better)\n",
      "\n",
      "== Variant B: augment_batch (shift+rot+shear+elastic) ==\n",
      "[augment_batch: all ops] Training on 150,100 samples (orig 60,000)...\n",
      "[augment_batch: all ops] Test accuracy: 0.9780\n",
      "[augment_batch: all ops] Error-rate change vs baseline: -9% (negative is better)\n",
      "\n",
      "== Optional ablations (smaller sets suggested if time is tight) ==\n",
      "[augment_batch: shift-only] Training on 150,131 samples (orig 60,000)...\n",
      "[augment_batch: shift-only] Test accuracy: 0.9772\n",
      "[augment_batch: shift-only] Error-rate change vs baseline: -5% (negative is better)\n",
      "[augment_batch: shift+rot] Training on 149,863 samples (orig 60,000)...\n",
      "[augment_batch: shift+rot] Test accuracy: 0.9773\n",
      "[augment_batch: shift+rot] Error-rate change vs baseline: -6% (negative is better)\n",
      "[augment_batch: shift+rot+shear] Training on 150,096 samples (orig 60,000)...\n",
      "[augment_batch: shift+rot+shear] Test accuracy: 0.9784\n",
      "[augment_batch: shift+rot+shear] Error-rate change vs baseline: -10% (negative is better)\n",
      "[augment_batch: all+elastic] Training on 150,188 samples (orig 60,000)...\n",
      "[augment_batch: all+elastic] Test accuracy: 0.9782\n",
      "[augment_batch: all+elastic] Error-rate change vs baseline: -10% (negative is better)\n",
      "\n",
      "== Summary ==\n",
      "Baseline (none):           0.9759\n",
      "Four-shift:                0.9805\n",
      "augment_batch (all ops):   0.9780\n",
      "augment_batch       shift-only: 0.9772\n",
      "augment_batch        shift+rot: 0.9773\n",
      "augment_batch  shift+rot+shear: 0.9784\n",
      "augment_batch      all+elastic: 0.9782\n"
     ]
    }
   ],
   "source": [
    "# =========================================================\n",
    "# Experiment: randomized augment_batch vs four-shift vs none\n",
    "# =========================================================\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# If best_params or baseline_acc don’t exist (fresh kernel), tune quickly & compute baseline.\n",
    "try:\n",
    "    _ = best_params\n",
    "except NameError:\n",
    "    from sklearn.experimental import enable_halving_search_cv  # noqa: F401\n",
    "    from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "    # Quick tune on a subset to keep things brisk.\n",
    "    tune_n = min(20_000, len(X_train))\n",
    "    rng_tune = np.random.default_rng(123)\n",
    "    subset_idx = rng_tune.choice(len(X_train), size=tune_n, replace=False)\n",
    "    X_tune, y_tune = X_train[subset_idx], y_train[subset_idx]\n",
    "\n",
    "    param_grid = {\n",
    "        \"n_neighbors\": [3, 4, 5, 6, 7, 9],\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"p\": [1, 2],\n",
    "        \"leaf_size\": [15, 30],\n",
    "    }\n",
    "    halving = HalvingGridSearchCV(\n",
    "        KNeighborsClassifier(n_jobs=-1),\n",
    "        param_grid=param_grid,\n",
    "        factor=2,\n",
    "        resource=\"n_samples\",\n",
    "        max_resources=tune_n,\n",
    "        scoring=\"accuracy\",\n",
    "        cv=3,\n",
    "        n_jobs=-1,\n",
    "        verbose=1,\n",
    "        random_state=123,\n",
    "        refit=True,\n",
    "    )\n",
    "    halving.fit(X_tune, y_tune)\n",
    "    best_params = halving.best_params_\n",
    "    print(\"Best params (auto-tuned in this block):\", best_params)\n",
    "\n",
    "# --- Transform primitives (conservative) ---\n",
    "from scipy.ndimage import shift, rotate, affine_transform, map_coordinates, gaussian_filter\n",
    "\n",
    "def shift_image(image, dx, dy):\n",
    "    im = image.reshape(28, 28)\n",
    "    return shift(im, [dy, dx], mode=\"constant\", cval=0.0, order=1).ravel()\n",
    "\n",
    "def rotate_image(image, degrees):\n",
    "    im = image.reshape(28, 28)\n",
    "    return rotate(im, angle=degrees, reshape=False, mode=\"constant\", cval=0.0, order=1).ravel()\n",
    "\n",
    "def shear_image(image, shear_x=0.0, shear_y=0.0):\n",
    "    im = image.reshape(28, 28)\n",
    "    cx = cy = 13.5\n",
    "    Sh = np.array([[1, -shear_x, 0],\n",
    "                   [-shear_y, 1, 0],\n",
    "                   [0, 0, 1]])\n",
    "    T1 = np.array([[1,0,-cx],[0,1,-cy],[0,0,1]])\n",
    "    T2 = np.array([[1,0,cx],[0,1,cy],[0,0,1]])\n",
    "    A = (T2 @ Sh @ T1)[:2, :]\n",
    "    return affine_transform(im, matrix=A[:,:2], offset=A[:,2], output_shape=(28,28),\n",
    "                            order=1, mode=\"constant\", cval=0.0).ravel()\n",
    "\n",
    "def elastic_deform(image, alpha=34, sigma=4):\n",
    "    im = image.reshape(28, 28)\n",
    "    rng = np.random.default_rng()\n",
    "    dx = gaussian_filter(rng.standard_normal(im.shape), sigma, mode=\"reflect\") * alpha\n",
    "    dy = gaussian_filter(rng.standard_normal(im.shape), sigma, mode=\"reflect\") * alpha\n",
    "    x, y = np.meshgrid(np.arange(28), np.arange(28), indexing='xy')\n",
    "    coords = np.vstack([(y + dy).ravel(), (x + dx).ravel()])\n",
    "    deformed = map_coordinates(im, coords, order=1, mode=\"constant\", cval=0.0).reshape(28, 28)\n",
    "    return deformed.ravel()\n",
    "\n",
    "# --- Deterministic four-shift augmentation (reference) ---\n",
    "def augment_four_translations(X_arr, y_arr):\n",
    "    X_aug = [X_arr]; y_aug = [y_arr]\n",
    "    for dx, dy in ((-1,0),(1,0),(0,1),(0,-1)):\n",
    "        X_aug.append(np.vstack([shift_image(img, dx, dy) for img in X_arr]))\n",
    "        y_aug.append(y_arr)\n",
    "    X_out = np.concatenate(X_aug, axis=0)\n",
    "    y_out = np.concatenate(y_aug, axis=0)\n",
    "    idx = np.random.default_rng(123).permutation(len(X_out))\n",
    "    return X_out[idx], y_out[idx]\n",
    "\n",
    "# --- Randomized augmentation with multiple ops (your request) ---\n",
    "def augment_batch(X, y, max_aug_per_image=2, ops=(\"shift\",\"rot\",\"shear\",\"elastic\"),\n",
    "                  probs=None, rng=None):\n",
    "    \"\"\"\n",
    "    Randomly applies up to max_aug_per_image ops per image.\n",
    "    - ops: subset of {\"shift\",\"rot\",\"shear\",\"elastic\"}.\n",
    "    - probs: selection probabilities matching len(ops). If None, default weights are used.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng() if rng is None else rng\n",
    "    if probs is None:\n",
    "        # Favor shifts, then small rotations; shears rarer; elastic rarest.\n",
    "        # Adjust to taste, but keep elastic sparse to avoid artifacts.\n",
    "        default = {\"shift\":0.45, \"rot\":0.30, \"shear\":0.18, \"elastic\":0.07}\n",
    "        probs = np.array([default[o] for o in ops], dtype=float)\n",
    "        probs = probs / probs.sum()\n",
    "\n",
    "    X_aug_parts = [X]\n",
    "    y_aug_parts = [y]\n",
    "\n",
    "    for img, label in zip(X, y):\n",
    "        k = rng.integers(1, max_aug_per_image+1)\n",
    "        for _ in range(k):\n",
    "            op = rng.choice(ops, p=probs)\n",
    "            if op == \"shift\":\n",
    "                # one-pixel shift, axis chosen at random\n",
    "                if rng.random() < 0.5:\n",
    "                    dx, dy = rng.choice([-1, 1]), 0\n",
    "                else:\n",
    "                    dx, dy = 0, rng.choice([-1, 1])\n",
    "                aug = shift_image(img, dx, dy)\n",
    "            elif op == \"rot\":\n",
    "                deg = rng.choice([-10, -7, 7, 10])\n",
    "                aug = rotate_image(img, deg)\n",
    "            elif op == \"shear\":\n",
    "                sx = rng.uniform(-0.12, 0.12)\n",
    "                sy = 0.0  # keep vertical shear off by default\n",
    "                aug = shear_image(img, shear_x=sx, shear_y=sy)\n",
    "            else:  # elastic\n",
    "                aug = elastic_deform(img, alpha=34, sigma=4)\n",
    "            X_aug_parts.append(aug[np.newaxis, :])\n",
    "            y_aug_parts.append(np.array([label], dtype=y.dtype))\n",
    "\n",
    "    X_aug = np.concatenate(X_aug_parts, axis=0)\n",
    "    y_aug = np.concatenate(y_aug_parts, axis=0)\n",
    "\n",
    "    # Shuffle to dissolve blockiness\n",
    "    idx = rng.permutation(len(X_aug))\n",
    "    return X_aug[idx], y_aug[idx]\n",
    "\n",
    "# --- One-shot runner for a variant ---\n",
    "def run_variant(name, make_augmented, *, params, report_baseline=None):\n",
    "    \"\"\"Train KNN on augmented data returned by make_augmented(), evaluate on test set.\"\"\"\n",
    "    X_tr_aug, y_tr_aug = make_augmented()\n",
    "    print(f\"[{name}] Training on {len(X_tr_aug):,} samples (orig {len(X_train):,})...\")\n",
    "    clf = KNeighborsClassifier(**params, n_jobs=-1)\n",
    "    clf.fit(X_tr_aug, y_tr_aug)\n",
    "    acc = accuracy_score(y_test, clf.predict(X_test))\n",
    "    print(f\"[{name}] Test accuracy: {acc:.4f}\")\n",
    "    if report_baseline is not None:\n",
    "        base_acc = report_baseline\n",
    "        base_err = 1.0 - base_acc\n",
    "        err = 1.0 - acc\n",
    "        delta = (err / base_err) - 1.0 if base_err > 0 else 0.0\n",
    "        print(f\"[{name}] Error-rate change vs baseline: {delta:.0%} (negative is better)\")\n",
    "    return acc\n",
    "\n",
    "# --- Baseline (no augmentation) ---\n",
    "print(\"\\n== Baseline (no augmentation) ==\")\n",
    "knn_base = KNeighborsClassifier(**best_params, n_jobs=-1)\n",
    "knn_base.fit(X_train, y_train)\n",
    "baseline_acc = accuracy_score(y_test, knn_base.predict(X_test))\n",
    "print(f\"[baseline] Test accuracy: {baseline_acc:.4f}\")\n",
    "\n",
    "# --- Variant A: four fixed 1px shifts (reference from earlier) ---\n",
    "print(\"\\n== Variant A: Four-shift augmentation ==\")\n",
    "X4, y4 = augment_four_translations(X_train, y_train)\n",
    "acc_four = run_variant(\n",
    "    \"four-shift\",\n",
    "    make_augmented=lambda: (X4, y4),\n",
    "    params=best_params,\n",
    "    report_baseline=baseline_acc\n",
    ")\n",
    "\n",
    "# --- Variant B: randomized augment_batch (shift+rot+shear+elastic) ---\n",
    "print(\"\\n== Variant B: augment_batch (shift+rot+shear+elastic) ==\")\n",
    "rng = np.random.default_rng(42)\n",
    "acc_batch = run_variant(\n",
    "    \"augment_batch: all ops\",\n",
    "    make_augmented=lambda: augment_batch(\n",
    "        X_train, y_train,\n",
    "        max_aug_per_image=2,\n",
    "        ops=(\"shift\",\"rot\",\"shear\",\"elastic\"),\n",
    "        probs=None,  # use defaults\n",
    "        rng=rng\n",
    "    ),\n",
    "    params=best_params,\n",
    "    report_baseline=baseline_acc\n",
    ")\n",
    "\n",
    "# --- (Optional) Ablations to see which ops pull their weight ---\n",
    "print(\"\\n== Optional ablations (smaller sets suggested if time is tight) ==\")\n",
    "ablations = [\n",
    "    (\"shift-only\", (\"shift\",)),\n",
    "    (\"shift+rot\", (\"shift\",\"rot\")),\n",
    "    (\"shift+rot+shear\", (\"shift\",\"rot\",\"shear\")),\n",
    "    (\"all+elastic\", (\"shift\",\"rot\",\"shear\",\"elastic\")),\n",
    "]\n",
    "abl_results = {}\n",
    "for label, ops in ablations:\n",
    "    rng_local = np.random.default_rng(123)\n",
    "    acc = run_variant(\n",
    "        f\"augment_batch: {label}\",\n",
    "        make_augmented=lambda ops=ops, rng_local=rng_local: augment_batch(\n",
    "            X_train, y_train,\n",
    "            max_aug_per_image=2,\n",
    "            ops=ops,\n",
    "            probs=None,\n",
    "            rng=rng_local\n",
    "        ),\n",
    "        params=best_params,\n",
    "        report_baseline=baseline_acc\n",
    "    )\n",
    "    abl_results[label] = acc\n",
    "\n",
    "print(\"\\n== Summary ==\")\n",
    "print(f\"Baseline (none):           {baseline_acc:.4f}\")\n",
    "print(f\"Four-shift:                {acc_four:.4f}\")\n",
    "print(f\"augment_batch (all ops):   {acc_batch:.4f}\")\n",
    "for k, v in abl_results.items():\n",
    "    print(f\"augment_batch {k:>16}: {v:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
